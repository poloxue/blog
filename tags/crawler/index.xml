<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Crawler on POLOXUE's BLOG</title><link>https://www.poloxue.com/tags/crawler/</link><description>Recent content in Crawler on POLOXUE's BLOG</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Polo Xue All rights reserved</copyright><lastBuildDate>Thu, 25 Jul 2019 13:35:36 +0800</lastBuildDate><atom:link href="https://www.poloxue.com/tags/crawler/index.xml" rel="self" type="application/rss+xml"/><item><title>Colly 从入门到不放弃指南</title><link>https://www.poloxue.com/posts/2019-07-25-colly-from-zero-to-hero/</link><pubDate>Thu, 25 Jul 2019 13:35:36 +0800</pubDate><guid>https://www.poloxue.com/posts/2019-07-25-colly-from-zero-to-hero/</guid><description>平时比较喜欢逛逛问答平台，比如 stackvoerflow，最近想聚合下一些平台的技术问答，比如 stackoverflow。
要完成这个工作，肯定是离不开爬虫工具。于是，我就想着顺便抽时间研究了 Go 的一款爬虫框架 colly。
概要介绍 colly 是 Go 实现的比较有名的一款爬虫框架，而且 Go 在高并发和分布式场景的优势也正是爬虫技术所需要的。它的主要特点是轻量、快速，设计非常优雅，并且分布式的支持也非常简单，易于扩展。
如何学习 爬虫最有名的框架应该就是 Python 的 scrapy，很多人最早接触的爬虫框架就是它，我也不例外。它的文档非常齐全，扩展组件也很丰富。当我们要设计一款爬虫框架时，常会参考它的设计。之前看到一些文章介绍 Go 中也有类似 scrapy 的实现。
相比而言，colly 的学习资料就少的可怜了。刚看到它的时候，我总会情不自禁想借鉴我的 scrapy 使用经验，但结果发现这种生搬硬套并不可行。
到此，我们自然地想到去找些文章阅读，但结果是 colly 相关文章确实有点少，能找到的基本都是官方提供的，而且看起来似乎不是那么完善。没办法，慢慢啃吧！官方的学习资料通常都会有三处，分别是文档、案例和源码。
今天，暂时先从官方文档角度吧！正文开始。
官方文档 官方文档介绍着重使用方法，如果是有爬虫经验的朋友，扫完一遍文档很快。我花了点时间将官网文档的按自己的思路整理了一版。
主体内容不多，涉及安装、快速开始、如何配置、调试、分布式爬虫、存储、运用多收集器、配置优化、扩展。
其中的每篇文档都很短小，甚至是少的基本都不用翻页滚动。
如何安装 colly 的安装和其他的 Go 库安装一样简单。如下：
1 go get -u github.com/gocolly/colly 一行命令搞定。So easy!
快速开始 我们来通过一个 hello word 案例快速体验下 colly 的使用。步骤如下：
第一步，导入 colly。
1 import &amp;#34;github.com/gocolly/colly&amp;#34; 第二步，创建 collector。
1 c := colly.NewCollector() 第三步，事件监听，通过 callback 执行事件处理。
1 2 3 4 5 6 7 8 9 10 11 12 13 // Find and visit all links c.</description></item></channel></rss>